{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKDCTnj3sMqXLX3NsDkiM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aapoorv-tf/abs-summarizer-using-seq2seq/blob/main/seq2seq_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu8qjmkxN6EL",
        "outputId": "9ae355be-adc4-457b-b65d-ac04531fe208"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbaw7Pu2OAK4"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/gdrive/MyDrive/IR Project')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBdYv1bvOBZg"
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_datasets as tfds\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxyCHOiKOIsd"
      },
      "source": [
        "cnn = tfds.load(name=\"cnn_dailymail\")\n",
        "cnn = tfds.as_dataframe(cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrNsO1rbQeQU",
        "outputId": "d49ec5a7-3f11-4270-b4a6-8ff24c253174"
      },
      "source": [
        "import tensorflow as tf\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime')\n",
        " \n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.50.83.18:8470']\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.83.18:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.50.83.18:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CSQ580WOUlg"
      },
      "source": [
        "cnnt = pd.read_csv(\"/content/gdrive/MyDrive/IR Project/Dataset/CDataset/cnn_dailymail_train.csv\", nrows=90000)\n",
        "cnnv = pd.read_csv(\"/content/gdrive/MyDrive/IR Project/Dataset/CDataset/cnn_dailymail_val.csv\", nrows=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJcmwsUMQ91J"
      },
      "source": [
        "data = [cnnt,cnnv]\n",
        "data = pd.concat(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "rSjMuwqNRIEK",
        "outputId": "27fbca26-c632-4830-a43e-a659fd7b8d7b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundr...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops. Outside the office, author...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help cocaine traffickers .\\nRalph Mata, an internal affairs lieutenant, allegedly helped group get guns .\\nHe also arranged to pay two assassins in a murde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he r...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least three pints before driving car .\\nWas using phone when he veered across road in Yarmouth, Isle of Wight .\\nCrashed head-on into 28-year-old Rachel Titl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen President Vladimir Putin wrote a new chapter into Crimea's turbulent history, committing the region to a future returned to Russian domain. Sixty years prio...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to accept sanctions will hurt both sides .\\nTargeting Russia's business community would be one way of sapping their support for President Putin, she says ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Fleetwood are the only team still to have a 100% record in Sky Bet League One as a 2-0 win over Scunthorpe sent Graham Alexander’s men top of the table. The Cod Army are playing in the third tier ...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at Scunthorpe .\\nPeterborough, Bristol City, Chesterfield and Crawley all drop first points of the season .\\nStand-in striker Matt Done scores a hat-trick...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                                                                                                                                                               highlights\n",
              "0           0  ...  Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown...\n",
              "1           1  ...  Criminal complaint: Cop used his role to help cocaine traffickers .\\nRalph Mata, an internal affairs lieutenant, allegedly helped group get guns .\\nHe also arranged to pay two assassins in a murde...\n",
              "2           2  ...  Craig Eccleston-Todd, 27, had drunk at least three pints before driving car .\\nWas using phone when he veered across road in Yarmouth, Isle of Wight .\\nCrashed head-on into 28-year-old Rachel Titl...\n",
              "3           3  ...  Nina dos Santos says Europe must be ready to accept sanctions will hurt both sides .\\nTargeting Russia's business community would be one way of sapping their support for President Putin, she says ...\n",
              "4           4  ...  Fleetwood top of League One after 2-0 win at Scunthorpe .\\nPeterborough, Bristol City, Chesterfield and Crawley all drop first points of the season .\\nStand-in striker Matt Done scores a hat-trick...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wFQtGr1RJ0k",
        "outputId": "c2cc2f6f-7310-4f95-f6e7-f1d63cb46f8b"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tATPTKu-RN7_",
        "outputId": "a5b4f01e-a42c-4bd9-9799-7db602bb2897"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 100000 entries, 0 to 9999\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  100000 non-null  int64 \n",
            " 1   article     100000 non-null  object\n",
            " 2   highlights  100000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3XEibVR600",
        "outputId": "a643a821-911e-4f06-ddf1-eb914a1757ac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r4sSNM7R0mh"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    return (\" \".join(tokens)).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv8gfqCLSBPB"
      },
      "source": [
        "cleaned_article = []\n",
        "for t in data['article']:\n",
        "    cleaned_article.append(text_cleaner(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhHeQQ_FSKxA"
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aUWSFvSSb5"
      },
      "source": [
        "cleaned_summary = []\n",
        "for t in data['highlights']:\n",
        "    cleaned_summary.append(summary_cleaner(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXKAS1oQSbhp"
      },
      "source": [
        "data['cleaned_article'] = cleaned_article\n",
        "data['cleaned_summary'] = cleaned_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "QiQNgmaKTZt8",
        "outputId": "6a955db1-0111-492c-b0d2-c6845a9334ab"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "      <th>cleaned_article</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundr...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown...</td>\n",
              "      <td>associated press published est october updated est october bishop fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis virus late s...</td>\n",
              "      <td>bishop john folda  of north dakota  is taking time off after being diagnosed   he contracted the infection through contaminated food in italy   church members in fargo  grand forks and jamestown c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops. Outside the office, author...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help cocaine traffickers .\\nRalph Mata, an internal affairs lieutenant, allegedly helped group get guns .\\nHe also arranged to pay two assassins in a murde...</td>\n",
              "      <td>ralph mata internal affairs lieutenant miami dade police department working division investigates allegations wrongdoing cops outside office authorities allege year old longtime officer worked dru...</td>\n",
              "      <td>criminal complaint  cop used his role to help cocaine traffickers   ralph mata  an internal affairs lieutenant  allegedly helped group get guns   he also arranged to pay two assassins in a murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he r...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least three pints before driving car .\\nWas using phone when he veered across road in Yarmouth, Isle of Wight .\\nCrashed head-on into 28-year-old Rachel Titl...</td>\n",
              "      <td>drunk driver killed young woman head crash checking mobile phone jailed six years craig eccleston todd driving home night pub received text message reading replying veered across road driving roun...</td>\n",
              "      <td>craig eccleston todd      had drunk at least three pints before driving car   was using phone when he veered across road in yarmouth  isle of wight   crashed head on into    year old rachel titley...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen President Vladimir Putin wrote a new chapter into Crimea's turbulent history, committing the region to a future returned to Russian domain. Sixty years prio...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to accept sanctions will hurt both sides .\\nTargeting Russia's business community would be one way of sapping their support for President Putin, she says ...</td>\n",
              "      <td>breezy sweep pen president vladimir putin wrote new chapter crimea turbulent history committing region future returned russian domain sixty years prior ukraine breakaway peninsula signed away swif...</td>\n",
              "      <td>nina dos santos says europe must be ready to accept sanctions will hurt both sides   targeting russia business community would be one way of sapping their support for president putin  she says   b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Fleetwood are the only team still to have a 100% record in Sky Bet League One as a 2-0 win over Scunthorpe sent Graham Alexander’s men top of the table. The Cod Army are playing in the third tier ...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at Scunthorpe .\\nPeterborough, Bristol City, Chesterfield and Crawley all drop first points of the season .\\nStand-in striker Matt Done scores a hat-trick...</td>\n",
              "      <td>fleetwood team still record sky bet league one win scunthorpe sent graham alexander men top table cod army playing third tier first time history six promotions nine years remarkable ascent shows s...</td>\n",
              "      <td>fleetwood top of league one after     win at scunthorpe   peterborough  bristol city  chesterfield and crawley all drop first points of the season   stand in striker matt done scores a hat trick a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                                                                                                                                                          cleaned_summary\n",
              "0           0  ...  bishop john folda  of north dakota  is taking time off after being diagnosed   he contracted the infection through contaminated food in italy   church members in fargo  grand forks and jamestown c...\n",
              "1           1  ...  criminal complaint  cop used his role to help cocaine traffickers   ralph mata  an internal affairs lieutenant  allegedly helped group get guns   he also arranged to pay two assassins in a murder ...\n",
              "2           2  ...  craig eccleston todd      had drunk at least three pints before driving car   was using phone when he veered across road in yarmouth  isle of wight   crashed head on into    year old rachel titley...\n",
              "3           3  ...  nina dos santos says europe must be ready to accept sanctions will hurt both sides   targeting russia business community would be one way of sapping their support for president putin  she says   b...\n",
              "4           4  ...  fleetwood top of league one after     win at scunthorpe   peterborough  bristol city  chesterfield and crawley all drop first points of the season   stand in striker matt done scores a hat trick a...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsNP2IG1Tf9-",
        "outputId": "9f336c97-8b88-4c3e-c31b-7f27161167ef"
      },
      "source": [
        "wc = pd.DataFrame()\n",
        "wc['article_count'] = data['cleaned_article'].apply(lambda x: len(str(x).split()))\n",
        "for i in range(90,100):\n",
        "  var = wc['article_count'].values\n",
        "  var = np.sort(var,axis=None)\n",
        "  print('At {} percentile, word count is {}'.format(i,var[int(len(var)*(float(i)/100))]))\n",
        "print(\"100 percentile - \",var[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At 90 percentile, word count is 631\n",
            "At 91 percentile, word count is 648\n",
            "At 92 percentile, word count is 668\n",
            "At 93 percentile, word count is 688\n",
            "At 94 percentile, word count is 712\n",
            "At 95 percentile, word count is 738\n",
            "At 96 percentile, word count is 768\n",
            "At 97 percentile, word count is 804\n",
            "At 98 percentile, word count is 851\n",
            "At 99 percentile, word count is 910\n",
            "100 percentile -  1934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq0JLx6ZUXIH",
        "outputId": "06e9395c-6b6d-400d-f10d-e7ae495d5427"
      },
      "source": [
        "wc = pd.DataFrame()\n",
        "wc['summary_count'] = data['cleaned_summary'].apply(lambda x: len(str(x).split()))\n",
        "for i in range(90,100):\n",
        "  var = wc['summary_count'].values\n",
        "  var = np.sort(var,axis=None)\n",
        "  print('At {} percentile, word count is {}'.format(i,var[int(len(var)*(float(i)/100))]))\n",
        "print(\"100 percentile - \",var[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At 90 percentile, word count is 73\n",
            "At 91 percentile, word count is 75\n",
            "At 92 percentile, word count is 77\n",
            "At 93 percentile, word count is 79\n",
            "At 94 percentile, word count is 82\n",
            "At 95 percentile, word count is 85\n",
            "At 96 percentile, word count is 89\n",
            "At 97 percentile, word count is 94\n",
            "At 98 percentile, word count is 101\n",
            "At 99 percentile, word count is 113\n",
            "100 percentile -  1208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQ7bgvqUigl"
      },
      "source": [
        "max_len_art = 700\n",
        "max_len_summ = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY9Mm2sUCyns"
      },
      "source": [
        "cleaned_article =np.array(data['cleaned_article'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_article=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_article)):\n",
        "    if(len(cleaned_summary[i].split())<=max_len_summ and len(cleaned_article[i].split())<=max_len_art):\n",
        "        short_article.append(cleaned_article[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'article':short_article,'summary':short_summary})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbO_C2wq7Xjm"
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x: 'sostok '+ x +' eostok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "UdOa8dSBU-Pj",
        "outputId": "6527d824-a891-45b6-efc6-254e7953a89d"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86505</th>\n",
              "      <td>woman arrested suspicion drunk aircraft allegedly stripped flight jamaica exposed year old woman south west london arrested police british airways flight landed gatwick airport yesterday kingston ...</td>\n",
              "      <td>sostok    year old woman from south west london arrested on arrival at gatwick   woman was drunk and had stripped off on flight from jamaica   the woman caused disruption after performing a solo s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86506</th>\n",
              "      <td>fundraiser pregnant widow whose husband killed suddenly tragic snowmobile accident earned space five days jeffrey kinn year old metal worker greenville new york life insurance died last thursday h...</td>\n",
              "      <td>sostok jeffrey kinn  a    year old metal worker from greenville  was killed in a head on collision between two snowmobiles   his wife tyler kinn      is six months pregnant with their first child ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86507</th>\n",
              "      <td>peacocks birds paradise male birds well known showing brightly coloured plumage way attracting mate however new research suggested males birds may actually growing less distinct female counterpart...</td>\n",
              "      <td>sostok study was conducted by researchers at university of wisconsin milwaukee   they measured the male and female plumage colour of     bird species   the researchers found some species show diff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86508</th>\n",
              "      <td>year old woman regular brushes death one year pronounced clinically dead times sara brautigam four years ago diagnosed postural orthostatic tachycardia syndrome condition makes heart race standing...</td>\n",
              "      <td>sostok the    year old has regular brushes with death due to rare heart condition   condition means she has palpitations that cause her heart to stop beating   in one year alone ms brautigam was p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86509</th>\n",
              "      <td>chilean girl plea via social media assisted suicide caught attention person teen thinks could make happen president michelle bachelet bachelet visited year old valentina maureira saturday girl vid...</td>\n",
              "      <td>sostok    year old valentina maureira suffers from cystic fibrosis   in a video  she asks the president to allow her to have an assisted suicide   eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                       article                                                                                                                                                                                                  summary\n",
              "86505  woman arrested suspicion drunk aircraft allegedly stripped flight jamaica exposed year old woman south west london arrested police british airways flight landed gatwick airport yesterday kingston ...  sostok    year old woman from south west london arrested on arrival at gatwick   woman was drunk and had stripped off on flight from jamaica   the woman caused disruption after performing a solo s...\n",
              "86506  fundraiser pregnant widow whose husband killed suddenly tragic snowmobile accident earned space five days jeffrey kinn year old metal worker greenville new york life insurance died last thursday h...  sostok jeffrey kinn  a    year old metal worker from greenville  was killed in a head on collision between two snowmobiles   his wife tyler kinn      is six months pregnant with their first child ...\n",
              "86507  peacocks birds paradise male birds well known showing brightly coloured plumage way attracting mate however new research suggested males birds may actually growing less distinct female counterpart...  sostok study was conducted by researchers at university of wisconsin milwaukee   they measured the male and female plumage colour of     bird species   the researchers found some species show diff...\n",
              "86508  year old woman regular brushes death one year pronounced clinically dead times sara brautigam four years ago diagnosed postural orthostatic tachycardia syndrome condition makes heart race standing...  sostok the    year old has regular brushes with death due to rare heart condition   condition means she has palpitations that cause her heart to stop beating   in one year alone ms brautigam was p...\n",
              "86509  chilean girl plea via social media assisted suicide caught attention person teen thinks could make happen president michelle bachelet bachelet visited year old valentina maureira saturday girl vid...                                                sostok    year old valentina maureira suffers from cystic fibrosis   in a video  she asks the president to allow her to have an assisted suicide   eostok"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fniNgEF9V6F0",
        "outputId": "a1f2027c-f386-4b7d-8606-09945b0fcdbf"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86510, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ehube0oVq2-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(np.array(df['article']),np.array(df['summary']),test_size=0.3,random_state=0,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTSjDOdv7tKr",
        "outputId": "466c885b-40a6-44ff-9bce-c700e9b3fa00"
      },
      "source": [
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "#rare words coverage for article\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 54.28225305657074\n",
            "Total Coverage of rare words: 0.7810724568042784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixEVwmVBXpzF"
      },
      "source": [
        "x_tokenizer = Tokenizer(num_words = tot_cnt-cnt)\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "x_train    =   x_tokenizer.texts_to_sequences(x_train) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "x_train    =   pad_sequences(x_train,  maxlen=max_len_art, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_art, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlElMloxY2yU",
        "outputId": "a8ee304e-f543-4478-d535-f820b7bc0fa5"
      },
      "source": [
        "x_voc_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196463"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0qtgZkB77p-",
        "outputId": "51badb32-8cbb-4a0d-e262-7e5d85f0393a"
      },
      "source": [
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "# rare words coverage in summary\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 61.98465231811055\n",
            "Total Coverage of rare words: 2.381947225800399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjt86Qs5XtZ5"
      },
      "source": [
        "y_tokenizer = Tokenizer(num_words = tot_cnt - cnt)\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "y_train    =   y_tokenizer.texts_to_sequences(y_train) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "y_train    =   pad_sequences(y_train, maxlen=max_len_summ, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summ, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOjnVj10Y911",
        "outputId": "43a75dd1-2f52-4c13-8763-815e0b94299a"
      },
      "source": [
        "y_voc_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72064"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJocDggGzgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aff00d1-4af1-4ad4-b692-0a5dc7e49431"
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60557, 60557)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxofophc91Ni"
      },
      "source": [
        "#deleting empty rows\n",
        "ind=[]\n",
        "for i in range(len(y_train)):\n",
        "    cnt=0\n",
        "    for j in y_train[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_train=np.delete(y_train,ind, axis=0)\n",
        "x_train=np.delete(x_train,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE2BtQ3I92Aj"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqO94qP2Y_S7"
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim=300\n",
        "embedding_dim=100\n",
        "\n",
        "def seq2seq():\n",
        "  \n",
        "  global encoder_inputs\n",
        "  global enc_emb\n",
        "  global encoder_outputs\n",
        "  global state_h\n",
        "  global state_c\n",
        "  global decoder_inputs\n",
        "  global dec_emb_layer\n",
        "  global decoder_lstm\n",
        "  global decoder_dense\n",
        "  encoder_inputs = Input(shape=(max_len_art,))\n",
        "  #embedding layer\n",
        "  \n",
        "  enc_emb =  Embedding(x_voc_size, embedding_dim,trainable=True)(encoder_inputs)\n",
        "  #encoder lstm 1\n",
        "  encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "  encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "  #encoder lstm 2\n",
        "  encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "  encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "    #encoder lstm 3\n",
        "  encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "  \n",
        "  encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "  \n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  #embedding layer\n",
        "  \n",
        "  dec_emb_layer = Embedding(y_voc_size, embedding_dim,trainable=True)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  \n",
        "  decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "  decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "  #dense layer\n",
        "  \n",
        "  decoder_dense =  TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwAyvflPHbGX",
        "outputId": "a3c704a0-daac-4b7e-8470-89bcc21562a8"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  model1=seq2seq()\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 700)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 700, 100)     19646300    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 700, 300), ( 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 700, 300), ( 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    7206400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 700, 300), ( 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 72064)  21691264    lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 50,948,764\n",
            "Trainable params: 50,948,764\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho62-lA6ZbYd"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "nadam = optimizers.Nadam(lr=0.0001,\n",
        "                         beta_1=0.9,\n",
        "                         beta_2=0.999,\n",
        "                         epsilon=1e-8, \n",
        "                         schedule_decay=0.004)\n",
        "model1.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=nadam,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZWbOhp3Zh6L"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SDv6D_-ZiNc",
        "outputId": "f095f49f-d35a-47f1-f34a-d939bcdd50cf"
      },
      "source": [
        "history=model1.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:],epochs=10,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "474/474 [==============================] - 898s 2s/step - loss: 5.9118 - acc: 0.4051 - val_loss: 4.6056 - val_acc: 0.4136\n",
            "Epoch 2/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.5270 - acc: 0.4195 - val_loss: 4.4099 - val_acc: 0.4368\n",
            "Epoch 3/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.4317 - acc: 0.4363 - val_loss: 4.3568 - val_acc: 0.4419\n",
            "Epoch 4/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.3719 - acc: 0.4425 - val_loss: 4.2949 - val_acc: 0.4498\n",
            "Epoch 5/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.3182 - acc: 0.4471 - val_loss: 4.2568 - val_acc: 0.4514\n",
            "Epoch 6/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.2887 - acc: 0.4488 - val_loss: 4.2341 - val_acc: 0.4538\n",
            "Epoch 7/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.2647 - acc: 0.4506 - val_loss: 4.2126 - val_acc: 0.4547\n",
            "Epoch 8/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.2414 - acc: 0.4518 - val_loss: 4.1901 - val_acc: 0.4560\n",
            "Epoch 9/10\n",
            "474/474 [==============================] - 827s 2s/step - loss: 4.2175 - acc: 0.4534 - val_loss: 4.1670 - val_acc: 0.4580\n",
            "Epoch 10/10\n",
            "474/474 [==============================] - 826s 2s/step - loss: 4.1914 - acc: 0.4561 - val_loss: 4.1408 - val_acc: 0.4613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5a6NIT5ZQIP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0HFC_WCv9D_"
      },
      "source": [
        "model1.save(\"/content/gdrive/MyDrive/IR Project/seq2seq_batch_128_epochs_10.h5\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNFnO2UeLjB"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyCJyuODeQKA"
      },
      "source": [
        "\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
        "                      state_h, state_c])\n",
        "\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_art, latent_dim))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py2NU9USlJQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8950d1e9-b7ca-44bc-f868-c5dd882dcab7"
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    7206400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 700, 300)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 72064)  21691264    lstm_3[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 29,378,864\n",
            "Trainable params: 29,378,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ear1RwReRuh"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index+1]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_len_summ-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3-7EiiTe-MQ"
      },
      "source": [
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbKdrgQVeyOp"
      },
      "source": [
        "for i in range(0,10):\n",
        "    print(\"Article:\",seq2text(x_val[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_art)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amw0lSHukJ1G",
        "outputId": "bbb38d2b-8a7f-446b-a700-7ed2f7bc0438"
      },
      "source": [
        "e_out, e_h, e_c = encoder_model.predict([x_val[2].reshape(1,max_len_art)])\n",
        "e_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-2.5858199e-03, -2.5425670e-03, -8.3016261e-04, ...,\n",
              "         -3.4304427e-03, -4.2542391e-03,  2.1860003e-03],\n",
              "        [-5.8229445e-03, -5.0611659e-03, -1.9341446e-03, ...,\n",
              "         -7.2180540e-03, -7.3330533e-03,  4.3918449e-03],\n",
              "        [-7.9106372e-03, -6.3761724e-03, -2.8139290e-03, ...,\n",
              "         -1.0367798e-02, -8.5317157e-03,  5.2703316e-03],\n",
              "        ...,\n",
              "        [-9.8920590e-01, -9.4010639e-01, -3.1490810e-02, ...,\n",
              "         -9.4217014e-01, -1.2793975e-01,  9.6344310e-01],\n",
              "        [-9.8920590e-01, -9.4010639e-01, -3.1490810e-02, ...,\n",
              "         -9.4217014e-01, -1.2793975e-01,  9.6344316e-01],\n",
              "        [-9.8920590e-01, -9.4010639e-01, -3.1490810e-02, ...,\n",
              "         -9.4217014e-01, -1.2793975e-01,  9.6344316e-01]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsFjNEobm4lN",
        "outputId": "654ee543-932e-4a1a-9a64-48a4b973ee48"
      },
      "source": [
        "np.zeros((1,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGy7_OjnBxc",
        "outputId": "2d41d9a8-de10-488d-dd76-6ff4e0eb049f"
      },
      "source": [
        "target_seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL_xX6v4mLAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4226e0-2a29-4e02-f0d5-79908ae7c022"
      },
      "source": [
        "target_seq = np.zeros((1,1))\n",
        "target_seq[0,0] = target_word_index['sostok']\n",
        "ot,h,c = decoder_model.predict([target_seq] + [e_out,e_h,e_c])\n",
        "ot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[5.6082464e-04, 7.4542157e-02, 2.2772681e-03, ...,\n",
              "         5.8579314e-08, 5.9814781e-08, 5.9788263e-08]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWacwk1WmU94",
        "outputId": "ac422de2-8bf0-4f50-d872-01959132a009"
      },
      "source": [
        "ot[0,-1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.6082261e-04, 7.4542493e-02, 2.2772676e-03, ..., 5.8579186e-08,\n",
              "       5.9814766e-08, 5.9788128e-08], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UDHRQ3fml0R",
        "outputId": "33e835db-29e4-4b2f-f7c9-8b353ff94b80"
      },
      "source": [
        "sampled_token_index = np.argmax(ot[0, -1, :])\n",
        "sampled_token_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SXI5tCKn973"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}